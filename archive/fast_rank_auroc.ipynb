{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing the studentized bootstrap\n",
    "\n",
    "In this post we'll examine three non-parametric tests: 1) the [Mann-Whitney U](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) (MNU) test, 2) [Wilcoxon signed rank](https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test) (WSR) test, and 3) the [Spearman correlation coefficient](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient). I've chosen these specific tests for three reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "\"\"\"\n",
    "SIMPLE HELPER FUNCTIONS\n",
    "\"\"\"\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def rvec(x):\n",
    "    return np.atleast_2d(x)\n",
    "\n",
    "def cvec(x):\n",
    "    return rvec(x).T\n",
    "\n",
    "def to_3d(mat):\n",
    "    return np.atleast_3d(mat).transpose(2,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Studentized) bootstrap support functions\n",
    "\n",
    "Suppose we have either one or two vector(s) of data $x$ and $y$. We may want to know something about the distribution of $x$, or the relationship between $x$ and $y$. It is also possible that $x$ and $y$ might be \"paired\", meaning they are jointly measured from some unit of observation (e.g. height and weight from the same person). The WSR and Spearman statistics are example of statistics for \"paired\" data, and hence require the lengths of the two vectors to be equivalent. In contrast, the MNU can test for differences between any two distributions, of possibly different lengths. \n",
    "\n",
    "The code block below provides for...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BOOTSTRAPER: CARRIES OUT STUDENTIZED BOOTSTRAP\n",
    "             ALLOWS FOR PAIRED SAMPLES\n",
    "\"\"\"\n",
    "def bs_gen(x, n_bs, n_s, y=None, is_paired=True):\n",
    "    n_x = len(x)\n",
    "    assert not ((y is None) and (is_paired==True))\n",
    "    if y is not None:\n",
    "        n_y = len(y)\n",
    "    else:\n",
    "        y_bs, y_s = None, None\n",
    "    # (i) Carry out the bootstrap\n",
    "    if is_paired:  # Implies y exists\n",
    "        assert len(x) == len(y)\n",
    "        x_bs = pd.Series(x).sample(frac=n_bs,replace=True)\n",
    "        x_bs_idx = x_bs.index\n",
    "        x_bs = x_bs.values.reshape([n_x,n_bs])\n",
    "        y_bs = pd.Series(y).iloc[x_bs_idx]\n",
    "        y_bs = y_bs.values.reshape([n_y,n_bs])\n",
    "    else:\n",
    "        x_bs = pd.Series(x).sample(frac=n_bs,replace=True).values.reshape([n_x,n_bs])\n",
    "        if y is not None:\n",
    "            y_bs = pd.Series(x).sample(frac=n_bs,replace=True).values.reshape([n_y,n_bs])\n",
    "    # (ii) Studentize\n",
    "    x_s = pd.DataFrame(x_bs).sample(frac=n_s,replace=True)\n",
    "    x_s_idx = x_s.index\n",
    "    x_s = x_s.values.reshape([n_s, n_x, n_bs]).transpose(1,2,0)\n",
    "    if is_paired:\n",
    "        y_s = pd.DataFrame(y_bs).iloc[x_s_idx]\n",
    "        y_s = y_s.values.reshape([n_s, n_y, n_bs]).transpose(1,2,0)\n",
    "    return x_bs, x_s, y_bs, y_s\n",
    "\n",
    "\"\"\"\n",
    "FUNCTION GENERATE CIs\n",
    "\"\"\"\n",
    "\n",
    "def gen_CI(stat, stat_bs, se_bs, se_s, pvals):\n",
    "    tt = ['student','normal','quant']\n",
    "    z_q = np.quantile(stat_bs,pvals.flat).reshape(pvals.shape)\n",
    "    z_n = stats.norm.ppf(pvals)\n",
    "    t_s = (stat_bs - stat) / se_s\n",
    "    z_s = np.quantile(t_s,pvals.flat).reshape(pvals.shape)\n",
    "    df = pd.DataFrame(np.r_[stat - se_bs*z_s[:,[1,0]], \n",
    "                            stat - se_bs*z_n[:,[1,0]],\n",
    "                            z_q],columns=['lb','ub'])\n",
    "    df.insert(0,'stat',stat)\n",
    "    df = df.assign(tt=np.repeat(tt,len(pvals)),alpha=np.tile(2*pvals[:,0],len(tt)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Spearman correlation coefficient\n",
    "\n",
    "The Spearman correlation coefficient will undergo the following transformation in order to ensure it is [consistent](https://www.tse-fr.eu/sites/default/files/medias/stories/SEMIN_09_10/STATISTIQUE/croux.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WRAPPER TO CALCULAE SPEARMAN'S CORRELATION COEFFICIENT WITH ADJUSTMENT FOR CONSISTENCY\n",
    "\"\"\"\n",
    "def spearman_trans(x):\n",
    "    return 2*np.sin(np.pi * x / 6)\n",
    "\n",
    "def rho_spearman(x,y):\n",
    "    return spearman_trans(stats.spearmanr(x,y)[0])\n",
    "\n",
    "\"\"\"\n",
    "VECTORIZED PAIRWISE SPEARMAN CORRELATION\n",
    "A : (n x p x s)\n",
    "n: sample size (rows of the data)\n",
    "p: columns of the data (could be bootstrapped columns)\n",
    "s: copies of the n x p matrix (could be studentized copies)\n",
    "\"\"\"\n",
    "def pairwise_cor(A, B):\n",
    "    assert A.shape == B.shape\n",
    "    n = A.shape[0]\n",
    "    if (len(A.shape) == 2):\n",
    "        mu_A, mu_B = rvec(A.mean(0)), rvec(B.mean(0))\n",
    "        se_A, se_B = A.std(axis=0,ddof=1), B.std(axis=0,ddof=1)\n",
    "    else:\n",
    "        mu_A, mu_B = to_3d(A.mean(0)), to_3d(B.mean(axis=0))\n",
    "        se_A, se_B = A.std(axis=0,ddof=1), B.std(axis=0,ddof=1)\n",
    "    D = np.sum((A - mu_A) * (B - mu_B),0) / (n-1)\n",
    "    return D / (se_A*se_B)\n",
    "\n",
    "def pairwise_spearman(A, B):\n",
    "    return spearman_trans(pairwise_cor(A, B))\n",
    "\n",
    "\"\"\"\n",
    "CARRY OUT BOOTSTRAP FOR SPEARMAN\n",
    "\"\"\"\n",
    "def bs_student_spearman(x, y, n_bs, n_s, alpha=0.05):\n",
    "    if isinstance(alpha, float) | isinstance(alpha,list):\n",
    "        alpha = np.array([alpha])\n",
    "    alpha = rvec(alpha)\n",
    "    assert len(x) == len(y)\n",
    "    assert np.all(alpha > 0) & np.all(alpha < 0.5)\n",
    "    # (i) Get baseline statistic\n",
    "    rho = rho_spearman(x, y)\n",
    "    n = len(x)\n",
    "    pvals = np.r_[alpha/2,1-alpha/2].T\n",
    "    # (ii) Transform data into ranks and sample with replacement\n",
    "    x_r, y_r = stats.rankdata(x), stats.rankdata(y)\n",
    "    # (iii) Get the bootstrapped and studentized samples\n",
    "    x_bs, x_s, y_bs, y_s = bs_gen(x=x_r, y=y_r, n_bs=n_bs, n_s=n_s, is_paired=True)\n",
    "    rho_bs = pairwise_spearman(x_bs, y_bs)\n",
    "    se_rho_bs = rho_bs.std(ddof=1)\n",
    "    se_rho_s = pairwise_spearman(x_s, y_s).std(axis=1,ddof=1)\n",
    "    # (iv) Get the confidence intervals for the different approaches\n",
    "    df = gen_CI(stat=rho, stat_bs=rho_bs, se_bs=se_rho_bs, se_s=se_rho_s, pvals=pvals)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulations below will do two things. First, we'll compare the type-1 error rate when the data comes from the same distribution. Then we'll examine the power, for different sample sizes. We'll use exponential data to show how the statistic functions for non-Gaussian data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho_gt: 0.001\n",
      "n: 25\n",
      "ETA: 3667 seconds (100 of 1000)\n",
      "ETA: 3603 seconds (200 of 1000)\n",
      "ETA: 3552 seconds (300 of 1000)\n",
      "ETA: 3495 seconds (400 of 1000)\n",
      "ETA: 3475 seconds (500 of 1000)\n",
      "ETA: 3439 seconds (600 of 1000)\n",
      "ETA: 3379 seconds (700 of 1000)\n",
      "ETA: 3318 seconds (800 of 1000)\n",
      "ETA: 3263 seconds (900 of 1000)\n",
      "ETA: 3207 seconds (1000 of 1000)\n",
      "n: 50\n",
      "ETA: 31294 seconds (100 of 1000)\n",
      "ETA: 17912 seconds (200 of 1000)\n",
      "ETA: 13350 seconds (300 of 1000)\n",
      "ETA: 11002 seconds (400 of 1000)\n",
      "ETA: 9533 seconds (500 of 1000)\n",
      "ETA: 8535 seconds (600 of 1000)\n",
      "ETA: 7778 seconds (700 of 1000)\n",
      "ETA: 7173 seconds (800 of 1000)\n",
      "ETA: 6680 seconds (900 of 1000)\n",
      "ETA: 6265 seconds (1000 of 1000)\n",
      "n: 75\n",
      "ETA: 50550 seconds (100 of 1000)\n",
      "ETA: 27008 seconds (200 of 1000)\n",
      "ETA: 18973 seconds (300 of 1000)\n",
      "ETA: 14906 seconds (400 of 1000)\n",
      "ETA: 12344 seconds (500 of 1000)\n",
      "ETA: 10749 seconds (600 of 1000)\n",
      "ETA: 9410 seconds (700 of 1000)\n",
      "ETA: 8358 seconds (800 of 1000)\n",
      "ETA: 7499 seconds (900 of 1000)\n",
      "ETA: 6775 seconds (1000 of 1000)\n",
      "n: 100\n",
      "ETA: 32413 seconds (100 of 1000)\n",
      "ETA: 15254 seconds (200 of 1000)\n",
      "ETA: 9396 seconds (300 of 1000)\n",
      "ETA: 6362 seconds (400 of 1000)\n",
      "ETA: 4453 seconds (500 of 1000)\n",
      "ETA: 3110 seconds (600 of 1000)\n",
      "ETA: 2090 seconds (700 of 1000)\n",
      "ETA: 1272 seconds (800 of 1000)\n",
      "ETA: 589 seconds (900 of 1000)\n",
      "ETA: 0 seconds (1000 of 1000)\n",
      "rho_gt: 0.253\n",
      "n: 25\n",
      "ETA: 217259 seconds (100 of 1000)\n",
      "ETA: 106848 seconds (200 of 1000)\n",
      "ETA: 70012 seconds (300 of 1000)\n",
      "ETA: 51577 seconds (400 of 1000)\n",
      "ETA: 40484 seconds (500 of 1000)\n",
      "ETA: 33072 seconds (600 of 1000)\n",
      "ETA: 27765 seconds (700 of 1000)\n",
      "ETA: 23772 seconds (800 of 1000)\n",
      "ETA: 20653 seconds (900 of 1000)\n",
      "ETA: 18148 seconds (1000 of 1000)\n",
      "n: 50\n",
      "ETA: 178405 seconds (100 of 1000)\n",
      "ETA: 87546 seconds (200 of 1000)\n",
      "ETA: 57198 seconds (300 of 1000)\n",
      "ETA: 42020 seconds (400 of 1000)\n",
      "ETA: 32951 seconds (500 of 1000)\n",
      "ETA: 26857 seconds (600 of 1000)\n",
      "ETA: 22465 seconds (700 of 1000)\n",
      "ETA: 19148 seconds (800 of 1000)\n",
      "ETA: 16572 seconds (900 of 1000)\n",
      "ETA: 14471 seconds (1000 of 1000)\n",
      "n: 75\n",
      "ETA: 141619 seconds (100 of 1000)\n",
      "ETA: 69011 seconds (200 of 1000)\n",
      "ETA: 44628 seconds (300 of 1000)\n",
      "ETA: 32373 seconds (400 of 1000)\n",
      "ETA: 24897 seconds (500 of 1000)\n",
      "ETA: 19816 seconds (600 of 1000)\n",
      "ETA: 16131 seconds (700 of 1000)\n",
      "ETA: 13316 seconds (800 of 1000)\n",
      "ETA: 11091 seconds (900 of 1000)\n",
      "ETA: 9266 seconds (1000 of 1000)\n",
      "n: 100\n",
      "ETA: 85763 seconds (100 of 1000)\n",
      "ETA: 39212 seconds (200 of 1000)\n",
      "ETA: 23465 seconds (300 of 1000)\n",
      "ETA: 15440 seconds (400 of 1000)\n",
      "ETA: 10527 seconds (500 of 1000)\n",
      "ETA: 7160 seconds (600 of 1000)\n",
      "ETA: 4694 seconds (700 of 1000)\n",
      "ETA: 2791 seconds (800 of 1000)\n",
      "ETA: 1267 seconds (900 of 1000)\n",
      "ETA: 0 seconds (1000 of 1000)\n",
      "rho_gt: 0.141\n",
      "n: 25\n",
      "ETA: 105104 seconds (100 of 1000)\n",
      "ETA: 46927 seconds (200 of 1000)\n",
      "ETA: 27498 seconds (300 of 1000)\n",
      "ETA: 17757 seconds (400 of 1000)\n",
      "ETA: 11891 seconds (500 of 1000)\n",
      "ETA: 7963 seconds (600 of 1000)\n",
      "ETA: 5142 seconds (700 of 1000)\n",
      "ETA: 3012 seconds (800 of 1000)\n",
      "ETA: 1344 seconds (900 of 1000)\n",
      "ETA: 0 seconds (1000 of 1000)\n",
      "n: 50\n",
      "ETA: 110334 seconds (100 of 1000)\n",
      "ETA: 49446 seconds (200 of 1000)\n",
      "ETA: 29082 seconds (300 of 1000)\n",
      "ETA: 18850 seconds (400 of 1000)\n",
      "ETA: 12667 seconds (500 of 1000)\n",
      "ETA: 8513 seconds (600 of 1000)\n",
      "ETA: 5516 seconds (700 of 1000)\n",
      "ETA: 3243 seconds (800 of 1000)\n",
      "ETA: 1452 seconds (900 of 1000)\n",
      "ETA: 0 seconds (1000 of 1000)\n",
      "n: 75\n",
      "ETA: 120137 seconds (100 of 1000)\n",
      "ETA: 54098 seconds (200 of 1000)\n",
      "ETA: 31958 seconds (300 of 1000)\n",
      "ETA: 20801 seconds (400 of 1000)\n",
      "ETA: 14038 seconds (500 of 1000)\n",
      "ETA: 9473 seconds (600 of 1000)\n",
      "ETA: 6163 seconds (700 of 1000)\n",
      "ETA: 3638 seconds (800 of 1000)\n",
      "ETA: 1636 seconds (900 of 1000)\n",
      "ETA: 0 seconds (1000 of 1000)\n",
      "n: 100\n",
      "ETA: 135996 seconds (100 of 1000)\n",
      "ETA: 61296 seconds (200 of 1000)\n",
      "ETA: 36249 seconds (300 of 1000)\n",
      "ETA: 23621 seconds (400 of 1000)\n",
      "ETA: 15960 seconds (500 of 1000)\n",
      "ETA: 10781 seconds (600 of 1000)\n",
      "ETA: 7022 seconds (700 of 1000)\n",
      "ETA: 4149 seconds (800 of 1000)\n",
      "ETA: 1867 seconds (900 of 1000)\n",
      "ETA: 0 seconds (1000 of 1000)\n"
     ]
    }
   ],
   "source": [
    "seed = 1234\n",
    "nsim = 1000\n",
    "n_gt = int(1e6)\n",
    "n_seq = list(np.arange(25,101,25))\n",
    "scale_seq = [0, 5, 10]\n",
    "n_bs, n_s = 1000, 1000\n",
    "np.random.seed(seed)\n",
    "\n",
    "stime = time()\n",
    "holder = []\n",
    "for k, scale in enumerate(scale_seq):\n",
    "    v1_gt = np.random.exponential(size=n_gt)\n",
    "    v2_gt = np.random.exponential(size=n_gt)\n",
    "    if scale > 0:\n",
    "        v2_gt = v1_gt + np.random.exponential(scale=scale,size=n_gt)\n",
    "    rho_gt = rho_spearman(v1_gt, v2_gt)\n",
    "    print('rho_gt: %0.3f' % rho_gt)\n",
    "    for j, n in enumerate(n_seq):\n",
    "        print('n: %i' % n)\n",
    "        for i in range(nsim):\n",
    "            v1 = np.random.exponential(size=n)\n",
    "            v2 = np.random.exponential(size=n)\n",
    "            if scale > 0:\n",
    "                v2 = v1 + np.random.exponential(scale=scale,size=n)\n",
    "            tmp_df = bs_student_spearman(v1, v2, n_bs=n_bs, n_s=n_s, alpha=[0.05, 0.10, 0.2])\n",
    "            tmp_df = tmp_df.assign(rho=rho_gt,lam=scale,n=n, sim=i)\n",
    "            holder.append(tmp_df)\n",
    "            if (i + 1) % 100 == 0:        \n",
    "                nleft = nsim*(len(n_seq)-(j+1))*(len(scale_seq)-(k+1)) + (nsim - (i+1))\n",
    "                nsec = time() - stime\n",
    "                rate = (i+1) / nsec\n",
    "                eta = nleft / rate\n",
    "                print('ETA: %i seconds (%i of %i)' % (eta, i+1, nsim))\n",
    "df_sim_spearman = pd.concat(holder).reset_index(None, True)\n",
    "df_sim_spearman = df_sim_spearman.assign(rho=lambda x: np.where(x.lam==0,0,x.rho))\n",
    "df_sim_spearman.to_csv(os.path.join('../output/df_sim_spearman.csv'),index=False)\n",
    "\n",
    "# cn_gg = ['tt','n','alpha','scale']\n",
    "# dat_cov = df_sim.groupby(cn_gg).apply(lambda x: np.mean((x.lb<=0) & (x.ub>=0))).reset_index()\n",
    "# dat_cov.rename(columns={0:'coverage'},inplace=True)\n",
    "# dat_cov.pivot_table('coverage',cn_gg[:-1],'alpha')\n",
    "# df_sim.groupby(['alpha','tt']).apply(lambda x: pd.Series({'err_lb':np.mean(x.lb > 0),\n",
    "#                                                           'err_ub':np.mean(x.ub < 0),\n",
    "#                                                           'spread':np.mean(x.ub - x.lb)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3473144\r\n",
      "-rwxrwxrwx 1 edrysdale edrysdale   10308578 Feb 11 16:20 df_sim_spearman.csv\r\n",
      "-rwxrwxrwx 1 edrysdale edrysdale       6400 Feb 10 11:39 dat_suspect.csv\r\n",
      "-rwxrwxrwx 1 edrysdale edrysdale       1195 Feb 10 11:38 dup_test.csv\r\n",
      "-rwxrwxrwx 1 edrysdale edrysdale   49599805 Feb  2 17:18 y_agg.csv\r\n",
      "-rwxrwxrwx 1 edrysdale edrysdale         93 Feb  2 12:40 best_outcome.csv\r\n",
      "-rwxrwxrwx 1 edrysdale edrysdale        124 Feb  2 12:39 best_mdl.csv\r\n",
      "-rwxrwxrwx 1 edrysdale edrysdale      54587 Feb  2 12:31 cpt_anno_organ.csv\r\n",
      "-rwxrwxrwx 1 edrysdale edrysdale      83222 Feb  2 12:31 cpt_anno_group.csv\r\n",
      "-rwxrwxrwx 1 edrysdale edrysdale      44374 Feb  2 12:31 cpt_anno.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lt ../output | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Mann-Whitney U statistic\n",
    "\n",
    "1. DISCUSS FORMULA FOR STATISTIC, AS WELL AS ASYMPTOTIC DIST\n",
    "2. MENTION THAT WHEN THERE ARE \"TIES\", THE FORMULA FOR THE SE NEEDS TO SHRINK\n",
    "3. THIS MEANS THAT THE BOOTSTRAP VARIANCE WILL BE \"CONSERVATIVE\" LINK THE PREVIOUS POST, AND WILL BE UNDERPOWERED\n",
    "4. THIS MEANS THAT UNFORTUNATELY WE STILL NEED TO RANK THE BOOTSTRAPS. HOWEVER, WE CAN BOOTSTRAP THE RANKS FOR THE STUDENTIZED COMPONENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BOOTSTRAP MWU\n",
    "\"\"\"\n",
    "def bs_student_mwu(x, y, n_bs, n_s, alpha=0.05):\n",
    "    if isinstance(alpha, float) | isinstance(alpha,list):\n",
    "        alpha = np.array([alpha])\n",
    "    alpha = rvec(alpha)\n",
    "    assert np.all(alpha > 0) & np.all(alpha < 0.5)\n",
    "    # (i) Get baseline statistic\n",
    "    pvals = np.r_[alpha/2,1-alpha/2].T    \n",
    "    n_x, n_y = len(x), len(y)\n",
    "    n_xy = n_x * n_y\n",
    "    # (ii) Transform to ranks and bootstrap\n",
    "    z = stats.rankdata(np.append(x, y))[:n_x]\n",
    "    z_bs, z_s, _, _ = bs_gen(x=z, n_bs=n_bs, n_s=n_s, is_paired=False)\n",
    "    # Calculate the MWU\n",
    "    mu = n_xy/2\n",
    "    se = np.sqrt((n_xy*(n_x+n_y+1))/12)\n",
    "    mnu = ((z.sum(0) - n_x*(n_x+1)/2) - mu) / se\n",
    "    mnu_bs = ((z_bs.sum(0) - n_x*(n_x+1)/2) - mu) / se\n",
    "    mnu_s = ((z_s.sum(0) - n_x*(n_x+1)/2) - mu) / se\n",
    "    se_mnu_bs = mnu_bs.std(ddof=1)\n",
    "    se_rho_s = mnu_s.std(axis=1,ddof=1)\n",
    "    df = gen_CI(stat=mnu, stat_bs=mnu_bs, se_bs=se_mnu_bs, se_s=se_rho_s, pvals=pvals)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsim = 1000\n",
    "n_bs = 900\n",
    "n1_seq = [50, 100, 150]\n",
    "n2_seq = n1_seq.copy()\n",
    "\n",
    "holder = []\n",
    "for n1 in n1_seq:\n",
    "    for n2 in n2_seq:\n",
    "        x1x2 = np.random.randn(n1+n2, nsim)\n",
    "        z = stats.rankdata(x1x2,axis=0)\n",
    "        z1, z2 = z[:n1], z[n1:]\n",
    "        mu1, mu2 = n1*(n1+1)/2 + n1*n2/2, n2*(n2+1)/2 + n1*n2/2\n",
    "        mnu1 = z1.sum(0) - mu1\n",
    "        mnu2 = z2.sum(0) - mu2\n",
    "        holder.append(pd.DataFrame({'u1':mnu1, 'u2':mnu2, 'n1':n1, 'n2':n2}))\n",
    "df_distU = pd.concat(holder).reset_index(None,True)\n",
    "df_distU = df_distU.melt(['n1','n2'],None,'tt','u')\n",
    "dat_se = df_distU.groupby(['n1','n2','tt']).u.std(ddof=1).reset_index()\n",
    "dat_se = dat_se.assign(theory=lambda x: np.sqrt((x.n1*x.n2*(x.n1 + x.n2 + 1))/12))\n",
    "dat_se.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard error of the bootstrapped ranks\n",
    "se_bs = np.mean([np.std(pd.Series(z1[:,j]).sample(frac=n_bs,replace=True).values.reshape([n1,n_bs]).sum(0) - mu1,ddof=1) for j in range(nsim)])\n",
    "print(se_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1_bs = pd.DataFrame(z1).sample(frac=n_bs,replace=True).values.reshape([n_bs, n1, nsim]).transpose(1,2,0)\n",
    "mnu1_bs = z1_bs.sum(0) - mu1\n",
    "print(z1.sum(0).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1_bs = pd.Series(z1[:,0]).sample(frac=n_bs,replace=True).values.reshape([n1,n_bs])\n",
    "mask_z1_bs = pd.DataFrame(z1_bs).apply(lambda x: x.duplicated(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[1,2,1,1,2,3],'b':list(range(6,0,-1))})\n",
    "# Sort the unique values in each\n",
    "df = df.apply(lambda x: x.sort_values().values, 0)\n",
    "# Find the duplicates\n",
    "mask = df.apply(lambda x: x.duplicated(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean ranks of the bootstrap line up with the ranks of that realization\n",
    "sns.scatterplot(z1_bs.mean(0).mean(1), z1.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(z1_bs.std(0).mean(1), z1.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_bs2 = np.mean(\n",
    "    [np.std(stats.rankdata(pd.Series(x1x2[:,j]).sample(frac=n_bs,replace=True).values.reshape([n1+n2,n_bs]),axis=0)[:n1].sum(0) - mu1) for j in range(nsim)])\n",
    "print(se_bs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard error for ranking bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotnine.options.figure_size = (8,7)\n",
    "gg_distU = (ggplot(df_distU,aes(x='u',fill='tt')) + theme_bw() + \n",
    "            geom_density(alpha=0.5,color='black') + \n",
    "            facet_wrap('~n1+n2',scales='free',labeller=label_both) + \n",
    "            theme(subplots_adjust={'wspace': 0.05,'hspace':0.45},\n",
    "                  axis_text_y=element_blank()))\n",
    "gg_distU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
