{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the best performing models of each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "# Load the help functions\n",
    "from support.acc_funs import fast_auc, fast_decomp\n",
    "from support.support_funs import makeifnot, decomp_var\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Set directories\n",
    "dir_base = os.getcwd()\n",
    "dir_NSQIP = os.path.join(dir_base,'..')\n",
    "dir_output = os.path.join(dir_NSQIP, 'output')\n",
    "dir_figures = os.path.join(dir_NSQIP, 'figures')\n",
    "makeifnot(dir_figures)\n",
    "\n",
    "di_model = {'logit':'Logistic-L2', 'rf':'RandomForest', 'xgb':'XGBoost'}\n",
    "di_outcome = {'adv':'ADV', 'aki':'AKI', 'cns':'CNS',\n",
    "              'nsi':'nSSIs', 'ssi':'SSIs', 'unplan':'UPLN'}\n",
    "di_method = {'agg':'Aggregate', 'sub':'CPT-model'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dummy data to make sure fast approximations line up\n",
    "# y = np.array([1,1,1,0,0,0,0,0])\n",
    "# s = np.array([6,5,7,5,3,2,2,1])\n",
    "# g = np.array(['a','a','b','a','b','b','b','c'])\n",
    "# print(fast_decomp(y,s,g,ret_df=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading large CSV file\n"
     ]
    }
   ],
   "source": [
    "fn_output = pd.Series(os.listdir(dir_output))\n",
    "fn_best = fn_output[fn_output.str.contains('.csv$') & fn_output.str.contains('^best')].reset_index(None,True)\n",
    "\n",
    "fn_csv = 'df_best.csv'\n",
    "check_csv = fn_csv in os.listdir(dir_output)\n",
    "if not check_csv:\n",
    "    print('Loading data via loop')\n",
    "    holder = []\n",
    "    cn_keep = ['model','outcome','test_year','cpt','y','preds']\n",
    "    for fn in fn_best:\n",
    "        print('Loading file: %s' % fn)\n",
    "        path = os.path.join(dir_output, fn)\n",
    "        tmp_df = pd.read_csv(path, usecols=cn_keep)  #, nrows=10\n",
    "        tmp_df.rename(columns={'model':'method'},inplace=True)\n",
    "        mdl = fn.split('.')[0].split('_')[-1]\n",
    "        tmp_df.insert(0,'model',mdl)\n",
    "        holder.append(tmp_df)\n",
    "        del tmp_df\n",
    "        #break\n",
    "    df_nsqip = pd.concat(holder).reset_index(None, True)\n",
    "    del holder\n",
    "    df_nsqip.to_csv(os.path.join(dir_output, fn_csv), index=False)\n",
    "else:\n",
    "    print('Loading large CSV file')\n",
    "    df_nsqip = pd.read_csv(os.path.join(dir_output, fn_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model  method\n",
       "logit  agg       4668432\n",
       "       sub       3185519\n",
       "rf     agg       4668432\n",
       "       sub       3185519\n",
       "xgb    agg       4668432\n",
       "       sub       3185519\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nsqip.groupby(['model','method']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qq = df_nsqip.query('model==\"logit\" & test_year==2014 & outcome==\"agg_ssi1\"').groupby(['method','cpt']).size()\n",
    "# qq = df_nsqip.query('model==\"logit\"').groupby(['method','outcome','test_year','cpt']).size().reset_index()\n",
    "# qq.groupby(['method','outcome','test_year']).size().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.A) Get the decomposed scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading decomposition\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aki</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cns</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nsi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ssi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>unplan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  outcome  version\n",
       "0     adv        1\n",
       "1     aki        1\n",
       "2     cns        1\n",
       "3     nsi        4\n",
       "4     ssi        1\n",
       "5  unplan        2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_gg = ['model','test_year','outcome','method']\n",
    "\n",
    "fn_decomp = 'dat_decomp.csv'\n",
    "check_decomp = fn_decomp in os.listdir(dir_output)\n",
    "if not check_decomp:\n",
    "    print('Running decomposition')\n",
    "    stime = time()\n",
    "    dat_decomp = df_nsqip.groupby(cn_gg).apply(lambda x: fast_decomp(x.y.values, x.preds.values, x.cpt.values))\n",
    "    dtime = time() - stime\n",
    "    print('Took %0.1f seconds to run decomp' % dtime)\n",
    "    dat_decomp = dat_decomp.reset_index().drop(columns='level_'+str(len(cn_gg)))\n",
    "    dat_decomp.to_csv(os.path.join(dir_output, fn_decomp), index=False)\n",
    "else:\n",
    "    print('Loading decomposition')\n",
    "    dat_decomp = pd.read_csv(os.path.join(dir_output, fn_decomp))\n",
    "# Clean up the outcome label\n",
    "dat_decomp.outcome = dat_decomp.outcome.str.replace('agg_','')\n",
    "dat_decomp['version'] = dat_decomp.outcome.str.replace('[^0-9]','')\n",
    "dat_decomp.version = np.where(dat_decomp.version == '', '1', dat_decomp.version).astype(int)\n",
    "dat_decomp.outcome = dat_decomp.outcome.str.replace('[^a-z]','')\n",
    "# Subset to within\n",
    "dat_decomp_within = dat_decomp.query('tt == \"within\"').reset_index(None, True).drop(columns='tt')\n",
    "# Find the best outcome/version\n",
    "best_decomp_all = dat_decomp_within.groupby(['outcome','version']).auc.mean().reset_index()\n",
    "best_decomp_all = best_decomp_all.sort_values(['outcome','auc'],ascending=[True,False]).groupby('outcome').head(1)\n",
    "best_decomp_all = best_decomp_all.drop(columns='auc').reset_index(None,True)\n",
    "best_decomp_all\n",
    "# # Subset the decomposition\n",
    "# dat_decomp_within_best = best_decomp_all.merge(dat_decomp_within,'left',['outcome','version'])#.drop(columns=['version'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.B) Get within distribution as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading decomposition by the cpt\n"
     ]
    }
   ],
   "source": [
    "fn_decomp_cpt = 'dat_decomp_cpt.csv'\n",
    "check_decomp_cpt = fn_decomp_cpt in os.listdir(dir_output)\n",
    "if not check_decomp_cpt:\n",
    "    print('Running decomposition for within')\n",
    "    stime = time()\n",
    "    dat_decomp_cpt = df_nsqip.groupby(cn_gg).apply(lambda x: fast_decomp(x.y.values, x.preds.values, x.cpt.values, ret_df=True))\n",
    "    dtime = time() - stime\n",
    "    print('Took %0.1f seconds to run decomp' % dtime)\n",
    "    dat_decomp_cpt = dat_decomp_cpt.reset_index()\n",
    "    dat_decomp_cpt.to_csv(os.path.join(dir_output, fn_decomp_cpt), index=False)\n",
    "else:\n",
    "    print('Loading decomposition by the cpt')\n",
    "    dat_decomp_cpt = pd.read_csv(os.path.join(dir_output, fn_decomp_cpt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3.A) Decompose variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    360.000000\n",
       "mean       0.655480\n",
       "std        0.051711\n",
       "min        0.434036\n",
       "25%        0.635302\n",
       "50%        0.653020\n",
       "75%        0.671503\n",
       "max        0.835229\n",
       "Name: auc, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_decomp_within.auc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find best model for \n",
    "# best_decomp_mdl = dat_decomp_within_best.groupby(['outcome','method','model']).auc.mean().reset_index()\n",
    "# best_decomp_mdl = best_decomp_mdl.sort_values(['outcome','method','auc'],ascending=[True,True,False])\n",
    "# best_decomp_mdl = best_decomp_mdl.groupby(['outcome','method']).head(1).reset_index(None, True).drop(columns='auc')\n",
    "# dat_decomp_within_mdl = dat_decomp_within.merge(best_decomp_mdl,'left',['model','outcome','method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the average within AUROC\n",
    "# dat_auc_version = dat_decomp.query('tt==\"within\"').groupby(['model','outcome','method','version']).auc.mean().reset_index()\n",
    "# dat_auc_version = dat_auc_version.sort_values(['outcome','auc'],ascending=[True,False]).reset_index(None, True)\n",
    "# best_version = dat_auc_version.groupby(['outcome']).head(1).drop(columns='auc').reset_index(None, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Use figures to visualize\n",
    "\n",
    "1. Variation between no models: no free lunch\n",
    "2. Variation over time: fairly similar?\n",
    "3. Variation over method: aggregate models generally do the best\n",
    "4. Show within AUROC for winning models\n",
    "5. Distribution of within AUROC by...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3.A) Within AUROC performance is similar acorss models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlabs = [di_model[cc] for cc in dat_decomp_within_best.model.unique()]\n",
    "# gg_decomp_within = (ggplot(dat_decomp_within_best, aes(x='model',y='auc',color='model')) + \n",
    "#                     theme_bw() + geom_boxplot() + \n",
    "#                     facet_wrap('~outcome',labeller=labeller(outcome=di_outcome)) + \n",
    "#                     theme(legend_position='none',axis_title_x=element_blank(),axis_text_x=element_text(angle=90)) + \n",
    "#                     labs(y='Within-CPT AUROC') +\n",
    "#                     ggtitle('Within AUORIC variation over years/CPT-subset') + \n",
    "#                     scale_x_discrete(labels=xlabs))\n",
    "# h, w = 4, 8\n",
    "# gg_decomp_within.save(os.path.join(dir_figures,'gg_decomp_within.png'),base_height=h, base_width=w, verbose=False)\n",
    "# plotnine.options.figure_size = (w, h)\n",
    "# gg_decomp_within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gg_decomp_mdl = (ggplot(dat_decomp_within_mdl, aes(x='outcome',y='auc',shape='model',color='test_year')) + \n",
    "#                     theme_bw() + geom_jitter(random_state=1, width=0.1, height=0) + \n",
    "#                     theme(axis_title_x=element_blank(),axis_text_x=element_text(angle=90)) + \n",
    "#                     labs(y='Within-CPT AUROC') +\n",
    "#                     ggtitle('Within AUORIC variation over years\\nOnly shows best performing model') + \n",
    "# #                 scale_color_discrete(name='Method',labels=list(di_method.values())) + \n",
    "#                 scale_shape_manual(name='Model', labels=list(di_model.values()), values=['$L$','$R$','$X$']) + \n",
    "#                 scale_x_discrete(labels=list(di_outcome.values())))\n",
    "# h, w = 4.5, 7\n",
    "# # gg_decomp_mdl.save(os.path.join(dir_figures,'gg_decomp_mdl.png'),base_height=h, base_width=w, verbose=False)\n",
    "# plotnine.options.figure_size = (w, h)\n",
    "# gg_decomp_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# di_method = {'agg':'Aggregate', 'sub':'Subset'}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
